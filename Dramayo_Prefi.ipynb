{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA from scratch**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Data Size: 85\n",
      "\n",
      "Processed Data (after PCA):\n",
      "[0.08491676787963251, -22.56688603869702]\n",
      "[-0.0019609865127218763, 0.5211380538970177]\n",
      "[-0.00233368904180926, 0.620184870094393]\n",
      "[-0.002111220777853496, 0.5610632609555148]\n",
      "[-0.002281383609293625, 0.6062845443488554]\n",
      "[-0.0016677280729195008, 0.44320374296932136]\n",
      "[-0.002833221379593852, 0.7529370887776086]\n",
      "[-0.0023081314395476987, 0.6133928605530441]\n",
      "[-0.0018945852840930306, 0.5034917280097597]\n",
      "[-0.001526470744807782, 0.40566418387839454]\n",
      "[-0.0022054380540562288, 0.586101785007176]\n",
      "[-0.0023165110935659174, 0.6156197787694899]\n",
      "[-0.002191036412133416, 0.5822745054232086]\n",
      "[-0.002219862024452182, 0.5899349984499251]\n",
      "[-0.00232022842971797, 0.6166076720137289]\n",
      "[-0.0022035786382604717, 0.585607639676293]\n",
      "[-0.0015333327196096818, 0.40748777428605565]\n",
      "[-0.0022317907463149183, 0.5931050921026326]\n",
      "[-0.0022224703875615547, 0.5906281787782226]\n",
      "[-0.002319918824740852, 0.6165253935614269]\n",
      "[-0.002301404777986945, 0.6116052300455148]\n",
      "[-0.0017114536572193425, 0.4548239482892961]\n",
      "[-0.002258498276282991, 0.6002026983848092]\n",
      "[-0.00024823476225179625, 0.06596913342862834]\n",
      "[-0.0030820541207361987, 0.8190651368919171]\n",
      "[-0.0008039661019113506, 0.21365640560561844]\n",
      "[-0.002110560507781419, 0.5608877922013055]\n",
      "[-0.002259113506505579, 0.6003661976637783]\n",
      "[-0.00045308712893594614, 0.12040926497333565]\n",
      "[-0.0007838141100908203, 0.20830095327008816]\n",
      "[-0.0019871465248840372, 0.5280901556782728]\n",
      "[-0.001522210050122402, 0.40453189147241225]\n",
      "[0.00235637555001037, -0.6262138777683085]\n",
      "[-0.0021557233680605716, 0.5728899579284078]\n",
      "[-0.002226584977750535, 0.5917216434755868]\n",
      "[-0.0021681236307441736, 0.5761853649701291]\n",
      "[-0.002283913647077492, 0.6069569094867169]\n",
      "[-0.002153747881812298, 0.5723649665262505]\n",
      "[-0.0019301027749428431, 0.5129306078494204]\n",
      "[-0.0023046872359308896, 0.6124775531001654]\n",
      "[-0.0023082543605794604, 0.6134255271863225]\n",
      "[-0.0018030150410198872, 0.4791566609603808]\n",
      "[-0.002160943315149685, 0.5742771745409736]\n",
      "[-0.0028255750722988183, 0.7509050596548268]\n",
      "[-0.0027187046906103894, 0.7225039348275912]\n",
      "[17.75721105650788, -4719.032156821166]\n",
      "[-0.0022747431814186163, 0.6045198307022417]\n",
      "[-0.002232840228545209, 0.5933839951565524]\n",
      "[0.0042177211043883485, -1.1208720477992729]\n",
      "[0.0010558632781885618, -0.28059883655842044]\n",
      "[-0.0003508657342441754, 0.09324362239970743]\n",
      "[0.018176391398091078, -4.8304305912455465]\n",
      "[-0.0023400112086169214, 0.6218650049067354]\n",
      "[0.0010491100616005495, -0.2788041489726618]\n",
      "[-0.0008220382432519977, 0.21845913143107312]\n",
      "[-0.0023295675461680963, 0.6190895702523763]\n",
      "[-0.0023541399604644084, 0.6256197631337936]\n",
      "[-0.0023359285627748048, 0.6207800295154674]\n",
      "[-0.002048451104596592, 0.5443820318126124]\n",
      "[-0.002334446012141249, 0.6203860372330305]\n",
      "[0.001834303072468057, -0.4874715492645006]\n",
      "[-0.002327264937448119, 0.6184776450711318]\n",
      "[-0.002456596378953833, 0.6528478639873407]\n",
      "[-0.0019578745362453403, 0.5203110368042259]\n",
      "[-0.0011989554204803014, 0.3186260030269788]\n",
      "[-0.0014451624046627834, 0.3840562483449944]\n",
      "[-0.0014067808198718853, 0.37385622694064063]\n",
      "[0.4460013617895869, -118.52620107816617]\n",
      "[2.1611825847567956, -574.3407611575049]\n",
      "[2.4928971599555374, -662.4949055368068]\n",
      "[1.6616227294796186, -441.5812296180092]\n",
      "[0.33337849681262105, -88.59633654435198]\n",
      "[5.259384698251322, -1397.697275611595]\n",
      "[-0.001977932805267466, 0.525641582024664]\n",
      "[-0.001977922449406855, 0.5256388299236117]\n",
      "[-0.001977922449406855, 0.5256388299236117]\n",
      "[-0.001977922449406855, 0.5256388299236117]\n",
      "[-0.001977922449406855, 0.5256388299236117]\n",
      "[0.008772003619012819, -2.3311863009423437]\n",
      "[-0.0019852049415771023, 0.5275741740845745]\n",
      "[-0.0019790705291459457, 0.5259439355615478]\n",
      "[-0.001977922449406855, 0.5256388299236117]\n",
      "[-0.0020919274060747896, 0.5559359894742281]\n",
      "[-0.0019642017465473748, 0.5219925119403412]\n",
      "[-0.0017180959546302678, 0.45658915877069306]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def parse_arff_file(file_path):\n",
    "    features, data = [], []\n",
    "    category_mapping_list = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data_started = False\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line or line.startswith('%') or line.lower().startswith('@relation'):\n",
    "                continue\n",
    "\n",
    "            if line.lower().startswith('@attribute'):\n",
    "                parts = line.split()\n",
    "                feature_name, feature_type = parts[1].strip(), 'nominal' if '{' in line else 'numeric'\n",
    "\n",
    "                if feature_type == 'nominal':\n",
    "                    values = line[line.index('{') + 1:line.index('}')].split(',')\n",
    "                    category_mapping_list.append({value: index for index, value in enumerate(values)})\n",
    "\n",
    "                features.append((feature_name, feature_type, values if feature_type == 'nominal' else 0))\n",
    "\n",
    "            if line.lower().startswith('@data'):\n",
    "                data_started = True\n",
    "                continue\n",
    "\n",
    "            if data_started:\n",
    "                data.append([category_mapping_list[i].get(value, float(value)) if features[i][1] == 'nominal' else float(value)\n",
    "                             for i, value in enumerate(line.split(','))])\n",
    "\n",
    "    return features, data\n",
    "\n",
    "def standardize(matrix):\n",
    "    means = [mean(col) for col in zip(*matrix)]\n",
    "    std_devs = [((sum((x - mean_i) ** 2 for x in col) / len(col)) ** 0.5) for mean_i, col in zip(means, zip(*matrix))]\n",
    "    return [[(col_i - mean_i) / std_dev for mean_i, std_dev, col_i in zip(means, std_devs, col)] for col in zip(*matrix)]\n",
    "\n",
    "def mean(vector):\n",
    "    return sum(vector) / len(vector)\n",
    "\n",
    "def covariance_matrix(matrix):\n",
    "    n = len(matrix)\n",
    "    num_features = len(matrix[0])\n",
    "    means = [mean(col) for col in zip(*matrix)]\n",
    "    cov_matrix = [[0] * num_features for _ in range(num_features)]\n",
    "\n",
    "    for i, mean_i in enumerate(means):\n",
    "        for j, mean_j in enumerate(means):\n",
    "            cov_matrix[i][j] = sum((val_i - mean_i) * (val_j - mean_j) for val_i, val_j in zip(matrix[i], matrix[j])) / (n - 1)\n",
    "\n",
    "    return cov_matrix\n",
    "\n",
    "def normalize(vector):\n",
    "    norm = sum(x**2 for x in vector)**0.5\n",
    "    return [x / norm for x in vector]\n",
    "\n",
    "def multiply(matrix, vector):\n",
    "    return [sum(x*y for x, y in zip(row, vector)) for row in matrix]\n",
    "\n",
    "def remove_duplicates(data):\n",
    "    unique_data = []\n",
    "    [unique_data.append(i) for i in data if i not in unique_data]\n",
    "    return unique_data\n",
    "\n",
    "def eigenvalues_and_eigenvectors(matrix, num_simulations=1000):\n",
    "    n = len(matrix)\n",
    "    vec = [1] * n\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        vec = normalize(multiply(matrix, vec))\n",
    "\n",
    "    eigenvalue = sum(x*y for x, y in zip(multiply(matrix, vec), vec))\n",
    "    eigenvector = vec\n",
    "\n",
    "    return eigenvalue, eigenvector\n",
    "\n",
    "def transform(matrix, eigenvectors, k):\n",
    "    return [[sum(row[j] * eigenvectors[i][j] for j in range(len(row))) for i in range(k)] for row in matrix]\n",
    "\n",
    "def pca(matrix, k):\n",
    "    num_features = len(matrix[0])\n",
    "    standardized_matrix = standardize(matrix)\n",
    "    cov_matrix = covariance_matrix(standardized_matrix)\n",
    "    eigenvalues, eigenvectors = eigenvalues_and_eigenvectors(cov_matrix)\n",
    "    sorted_indices = sorted(range(num_features), key=lambda k: eigenvalues, reverse=True)\n",
    "    eigenvectors = [[eigenvectors[i] for j in sorted_indices] for i in range(num_features)]\n",
    "    return transform(standardized_matrix, eigenvectors, k)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_paths = [\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2017.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2018.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2019.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2020.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2021 Q1.arff',\n",
    "    ]\n",
    "    \n",
    "    dataset = []\n",
    "    for file in file_paths:\n",
    "        features, dt = parse_arff(file)\n",
    "        for row in dt:\n",
    "            for i, (feature_name, feature_type, feature_values) in enumerate(features):\n",
    "                if feature_type == 'nominal':\n",
    "                    category_mapping = {value: index for index, value in enumerate(feature_values)}\n",
    "                    row[i] = category_mapping.get(row[i])\n",
    "                elif feature_type == 'numeric':\n",
    "                    try:\n",
    "                        row[i] = float(row[i])\n",
    "                    except Exception as e:\n",
    "                        row[i] = 0\n",
    "        dataset.extend(dt)\n",
    "\n",
    "    num_components = 2\n",
    "    processed_dataset = pca(dataset, num_components)\n",
    "\n",
    "    print(f\"\\nProcessed Data Size: {len(processed_dataset)}\")\n",
    "    print(\"\\nProcessed Data (after PCA):\")\n",
    "    for sample in processed_dataset:\n",
    "        print(sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD from Scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "U matrix:\n",
      "[[ 4.11939189e-02            -inf]\n",
      " [-9.51292912e-04             inf]\n",
      " [-1.13209440e-03             inf]\n",
      " [-1.02417296e-03             inf]\n",
      " [-1.10672054e-03             inf]\n",
      " [-8.09030498e-04             inf]\n",
      " [-1.37442221e-03             inf]\n",
      " [-1.11969617e-03             inf]\n",
      " [-9.19081055e-04             inf]\n",
      " [-7.40505246e-04             inf]\n",
      " [-1.06987864e-03             inf]\n",
      " [-1.12376121e-03             inf]\n",
      " [-1.06289227e-03             inf]\n",
      " [-1.07687585e-03             inf]\n",
      " [-1.12556453e-03             inf]\n",
      " [-1.06897662e-03             inf]\n",
      " [-7.43834054e-04             inf]\n",
      " [-1.08266258e-03             inf]\n",
      " [-1.07814119e-03             inf]\n",
      " [-1.12541434e-03            -inf]\n",
      " [-1.11643300e-03             inf]\n",
      " [-8.30242188e-04             inf]\n",
      " [-1.09561865e-03             inf]\n",
      " [-1.20421007e-04             inf]\n",
      " [-1.49513330e-03             inf]\n",
      " [-3.90011481e-04             inf]\n",
      " [-1.02385266e-03             inf]\n",
      " [-1.09591711e-03             inf]\n",
      " [-2.19796807e-04             inf]\n",
      " [-3.80235561e-04             inf]\n",
      " [-9.63983379e-04             inf]\n",
      " [-7.38438343e-04             inf]\n",
      " [ 1.14309984e-03            -inf]\n",
      " [-1.04576158e-03             inf]\n",
      " [-1.08013721e-03             inf]\n",
      " [-1.05177707e-03             inf]\n",
      " [-1.10794789e-03             inf]\n",
      " [-1.04480326e-03             inf]\n",
      " [-9.36310922e-04             inf]\n",
      " [-1.11802535e-03             inf]\n",
      " [-1.11975580e-03             inf]\n",
      " [-8.74659473e-04             inf]\n",
      " [-1.04829383e-03             inf]\n",
      " [-1.37071292e-03             inf]\n",
      " [-1.31886909e-03             inf]\n",
      " [ 8.61418929e+00             inf]\n",
      " [-1.10349921e-03             inf]\n",
      " [-1.08317169e-03             inf]\n",
      " [ 2.04605599e-03            -inf]\n",
      " [ 5.12209159e-04            -inf]\n",
      " [-1.70208252e-04             inf]\n",
      " [ 8.81753760e-03            -inf]\n",
      " [-1.13516134e-03             inf]\n",
      " [ 5.08933111e-04            -inf]\n",
      " [-3.98778446e-04            -inf]\n",
      " [-1.13009502e-03             inf]\n",
      " [-1.14201533e-03             inf]\n",
      " [-1.13318081e-03             inf]\n",
      " [-9.93722805e-04             inf]\n",
      " [-1.13246161e-03             inf]\n",
      " [ 8.89837590e-04            -inf]\n",
      " [-1.12897800e-03             inf]\n",
      " [-1.19171790e-03             inf]\n",
      " [-9.49783263e-04             inf]\n",
      " [-5.81624497e-04             inf]\n",
      " [-7.01061809e-04             inf]\n",
      " [-6.82442543e-04             inf]\n",
      " [ 2.16359435e-01            -inf]\n",
      " [ 1.04840990e+00            -inf]\n",
      " [ 1.20932775e+00            -inf]\n",
      " [ 8.06068739e-01            -inf]\n",
      " [ 1.61725029e-01            -inf]\n",
      " [ 2.55137675e+00            -inf]\n",
      " [-9.59513717e-04             inf]\n",
      " [-9.59508694e-04             inf]\n",
      " [-9.59508694e-04             inf]\n",
      " [-9.59508694e-04             inf]\n",
      " [-9.59508694e-04             inf]\n",
      " [ 4.25538106e-03            -inf]\n",
      " [-9.63041499e-04             inf]\n",
      " [-9.60065638e-04             inf]\n",
      " [-9.59508694e-04             inf]\n",
      " [-1.01481357e-03             inf]\n",
      " [-9.52852652e-04             inf]\n",
      " [-8.33464429e-04             inf]]\n",
      "\n",
      "Singular Values:\n",
      "[547.82468852   0.        ]\n",
      "\n",
      "V^T matrix:\n",
      "[[ 0.00376287 -0.99999292]\n",
      " [-0.99999292 -0.00376287]]\n",
      "\n",
      "Reconstructed Data:\n",
      "[[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/523zxdmx03x_6c0800br7tgh0000gn/T/ipykernel_7554/1621836199.py:21: RuntimeWarning: divide by zero encountered in divide\n",
      "  matrix_u = np.dot(matrix, matrix_v) / singular_values\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def svd(matrix, num_iterations=100):\n",
    "    matrix = np.array(matrix)\n",
    "    num_rows, num_cols = matrix.shape\n",
    "\n",
    "    # Step 1: Compute the covariance matrix\n",
    "    cov_matrix = (1 / (num_rows - 1)) * np.dot(matrix.T, matrix)\n",
    "\n",
    "    # Step 2: Compute eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "    # Step 3: Sort eigenvalues and corresponding eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    # Step 4: Compute the singular values and the matrices U and V\n",
    "    singular_values = np.sqrt(eigenvalues)\n",
    "    matrix_v = eigenvectors\n",
    "    matrix_u = np.dot(matrix, matrix_v) / singular_values\n",
    "\n",
    "    # Step 5: Truncate to the desired number of components\n",
    "    matrix_u = matrix_u[:, :num_iterations]\n",
    "    singular_values = singular_values[:num_iterations]\n",
    "    matrix_v = matrix_v[:, :num_iterations]\n",
    "\n",
    "    # Step 6: Reconstruct the matrix using the truncated SVD\n",
    "    reconstructed_matrix = np.dot(matrix_u, np.dot(np.diag(singular_values), matrix_v.T))\n",
    "\n",
    "    return matrix_u, singular_values, matrix_v.T, reconstructed_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_paths = [\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2017.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2018.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2019.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2020.arff',\n",
    "        r'/Users/llewelyndramayo/Desktop/DISCRETE/V4 data/2021 Q1.arff',\n",
    "    ]\n",
    "\n",
    "    # Use SVD on your processed dataset\n",
    "    num_components = 2\n",
    "    u, s, vt, reconstructed_data = svd(processed_dataset, num_iterations=num_components)\n",
    "\n",
    "    print(\"\\nU matrix:\")\n",
    "    print(u)\n",
    "\n",
    "    print(\"\\nSingular Values:\")\n",
    "    print(s)\n",
    "\n",
    "    print(\"\\nV^T matrix:\")\n",
    "    print(vt)\n",
    "\n",
    "    print(\"\\nReconstructed Data:\")\n",
    "    print(reconstructed_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA WITH SKL Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Data (sklearn PCA):\n",
      "[[-3.75929948 -0.22842634]\n",
      " [-3.87323055 -0.23078713]\n",
      " [-3.6960769  -0.22066703]\n",
      " ...\n",
      " [-3.72282839 -0.16900814]\n",
      " [-0.79484321 -0.11979951]\n",
      " [-3.75769923 -0.16898709]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'dataset' is the data you read using parse_arff_file\n",
    "X = np.array(dataset)\n",
    "\n",
    "# Standardize the data\n",
    "X_standardized = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Perform PCA with sklearn\n",
    "pca_sklearn = PCA(n_components=2)\n",
    "processed_dataset_sklearn = pca_sklearn.fit_transform(X_standardized)\n",
    "\n",
    "print(\"\\nProcessed Data (sklearn PCA):\")\n",
    "print(processed_dataset_sklearn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION:\n",
    "Comparing my custom PCA implementation with sklearn, I found overall similarity in results, indicating accurate implementation. Consistency in data standardization was crucial for alignment. Despite minor variations expected from algorithmic differences, the close correspondence underscores the reliability of the custom PCA algorithm, emphasizing the importance of careful implementation and parameter alignment.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVD with SKLearn Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "CONCLUSION : In comparing my custom Singular Value Decomposition (SVD) implementation with sklearn's TruncatedSVD, I found overall similarity in U, singular values, and $V^T$ matrices, indicating the core SVD algorithm's correctness. Small numerical differences exist, likely due to variations in numerical precision and underlying algorithms. This underscores the importance of code robustness, debugging, and continuous improvement for numerical algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (v3.11.5:cce6ba91b3, Aug 24 2023, 10:50:31) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
